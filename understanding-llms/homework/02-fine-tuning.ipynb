{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CmAe9tIzAM9"
      },
      "source": [
        "# Homework 2: Fine-tuning & Prompting of LMs (51 points)\n",
        "\n",
        "The focus of this homework is on one prominent fine-tuning technique -- reinforcement learning from human feedback -- and on critically thinking about prompting techniques and papers about language models\n",
        "\n",
        "### Logistics\n",
        "\n",
        "* submission deadline: June 3rd th 23:59 German time via Moodle\n",
        "  * please upload a **SINGLE .IPYNB FILE named Surname_FirstName_HW2.ipynb** containing your solutions of the homework.\n",
        "* please solve and submit the homework **individually**!\n",
        "* if you use Colab, to speed up the execution of the code on Colab, you can use the available GPU (if Colab resources allow). For that, before executing your code, navigate to Runtime > Change runtime type > GPU > Save.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDhAxqcIzAM_"
      },
      "source": [
        "## Exercise 1: Advanced prompting strategies (16 points)\n",
        "\n",
        "The lecture discussed various sophisticated ways of prompting language models for generating texts. Please answer the following questions about prompting techniques in context of different models, and write down your answers, briefly explaining them (max. 3 sentences). Feel free to actually try out some of the prompting strategies to play around with them and build your intuitions.\n",
        "\n",
        "> Consider the following language models:\n",
        "> * GPT-4, Qwen-2.5-Coder-32B, Mistral-24B-Instruct, Llama-2-70b-base.\n",
        ">  \n",
        "> Consider the following prompting / generation strategies:\n",
        "> * tree-of-thought reasoning, zero-shot chain-of-thought prompting, few-shot prompting, self-reflection prompting.\n",
        ">\n",
        "> For each model:\n",
        "> * which strategies do you think work well, and why?\n",
        ">\n",
        "> For each prompting strategy:\n",
        "> * Name an example task or context, and model, in which you would think they work best. Briefly justify why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0u8n5AgzAM_"
      },
      "source": [
        "## Exercise 2: RLHF for summarization (15 points)\n",
        "\n",
        "In this exercise, we want to fine-tune GPT-2 to generate human-like news summaries, following a procedure that is very similar to the example of the movie review generation from [sheet 4.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/04a-finetuning-RL.html). The exercise is based on the paper by [Ziegler et al. (2020)](https://arxiv.org/pdf/1909.08593).\n",
        "\n",
        "To this end, we will use the following components:\n",
        "* in order to initialize the policy, we use GPT-2 that was already fine-tuned for summarization, i.e., our SFT model is [this](https://huggingface.co/gavin124/gpt2-finetuned-cnn-summarization-v2)\n",
        "* as our reward model, we will use a task-specific reward signal, namely, the ROUGE score that evaluates a summary generated by a model against a human \"gold standard\" summary.\n",
        "* a dataset of CNN news texts and human-written summaries (for computing the rewards) for the fine-tuning which can be found [here](https://huggingface.co/datasets/abisee/cnn_dailymail). Please note that we will use the *validation* split because we only want to run short fine-tuning.\n",
        "\n",
        "**NOTE:** for building the datset and downloading the pretrained model, ~4GB of space will be used.\n",
        "\n",
        "> **YOUR TASK:**\n",
        ">\n",
        "> Your job for this task is to set up the **GRPO-based** training with the package `trl`, i.e., the set up step 3 of [this](https://cdn.openai.com/instruction-following/draft-20220126f/methods.svg) figure. GRPO (Group Relative Policy Optimization) is an RL algorithm that was proposed by [Shao et al. (2024)](https://arxiv.org/pdf/2402.03300) for the DeepSeek math model.\n",
        "> 1. Please complete the code or insert comments what a particular line of code does below where the comments says \"#### YOUR CODE / COMMENT HERE ####\". For this and for answering the questions, you might need to dig a bit deeper into the working of GRPO, the algorithm that we are using for training. You can find relevant information on the implementation, e.g., [here](https://huggingface.co/docs/trl/main/en/grpo_trainer).\n",
        "> 2. To test your implementation, you can run the training for ~250 steps, but you are NOT required to train the full model since it will take too long. We will NOT be evaluating your submission based on the performance of the model.\n",
        "> 3. Answer the questions below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_p0UVifCzAM_"
      },
      "outputs": [],
      "source": [
        "# !pip install gcsfs==2025.3.0 fsspec==2025.3.0 accelerate==1.6.0 trl==0.17.0 evaluate rouge_score datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "IwGGxvlTzANA",
        "outputId": "7b54929f-f988-4909-9317-45f0c80a8db3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'trl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-95092db86e21>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from trl import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mGRPOTrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mGRPOConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "from trl import (\n",
        "    GRPOTrainer,\n",
        "    GRPOConfig,\n",
        ")\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT-lh2zIzANA"
      },
      "outputs": [],
      "source": [
        "#### YOUR COMMENT HERE (what is the purpose of this code?) ####\n",
        "config = GRPOConfig(\n",
        "    #### YOUR COMMENT HERE (what is the meaning of each of the following parameters?) #####\n",
        "    learning_rate=1.41e-5,\n",
        "    #### YOUR COMMENT HERE ####\n",
        "    max_steps=250,\n",
        "    #### YOUR COMMENT HERE ####\n",
        "    per_device_train_batch_size=8,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    num_generations=8,\n",
        "    #### YOUR CODE HERE: set the number of overall training epochs to 1 ####\n",
        "    ,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    logging_steps=1,\n",
        "    #### YOUR COMMENT HERE####\n",
        "    report_to=\"none\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoDy-c_UzANB"
      },
      "source": [
        "We load the CNN dataset and truncate the texts to 512 tokens, because we don't want the training to be too memory heavy and we want to have \"available\" some tokens for the generation (GPT-2's context window size is 1024). Then we tokenize each text and pad it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y9JJJ_pzANB"
      },
      "outputs": [],
      "source": [
        "def build_dataset(\n",
        "        model_name,\n",
        "        dataset_name=\"abisee/cnn_dailymail\"\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Build dataset for training. This builds the dataset from `load_dataset`.\n",
        "\n",
        "    Args:\n",
        "        model_name (`str`):\n",
        "            The name of the SFT model to be used, so that the matchin tokenizer can be loaded.\n",
        "        dataset_name (`str`):\n",
        "            The name of the dataset to be loaded.\n",
        "\n",
        "    Returns:\n",
        "        dataloader (`torch.utils.data.DataLoader`):\n",
        "            The dataloader for the dataset.\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(#### YOUR CODE HERE ####)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'left'\n",
        "    # load the datasets\n",
        "    ds = load_dataset(dataset_name, '1.0.0', split=\"validation\")\n",
        "\n",
        "    def tokenize(sample):\n",
        "        sample[\"input_ids\"] = tokenizer.encode(\n",
        "            #### YOUR CODE HERE (hint: inspect the dataset to see how to access the input text)####,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "        # get the truncated natural language text, too\n",
        "        sample[\"prompt\"] = #### YOUR CODE HERE ####\n",
        "        sample[\"ground_truth\"] = #### YOUR CODE HERE ####\n",
        "        return sample\n",
        "\n",
        "    ds = ds.map(tokenize, batched=False)\n",
        "    ds.set_format(type=\"torch\")\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy2kT-NRzANB"
      },
      "outputs": [],
      "source": [
        "# use tokenizer from HF named: \"gavin124/gpt2-finetuned-cnn-summarization-v2\"\n",
        "# build the dataset\n",
        "dataset =  #### YOUR CODE HERE ####\n",
        "\n",
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKHJ36_czANB"
      },
      "outputs": [],
      "source": [
        "# inspect a sample of the dataset\n",
        "print(dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KWD6jwgzANB"
      },
      "source": [
        "We load the tokenizer corresponsing to the SFT GPT2 model that we already used above to pretokenize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Y1MDBxzANB"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(#### YOUR CODE HERE ####)\n",
        "\n",
        "tokenizer.padding_side='left'\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb6FSN6VzANB"
      },
      "source": [
        "Below, we define our custom reward function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Dj7THHAzANC"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def reward_fn(\n",
        "        output: list[str],\n",
        "        original_summary: list[str]\n",
        "    ):\n",
        "    \"\"\"\n",
        "    #### YOUR COMMENT HERE ####\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    for o, s in list(zip(output, original_summary)):\n",
        "      score = rouge.compute(predictions=[o.strip()], references=[s])[\"rouge1\"]\n",
        "      scores.append(torch.tensor(score))\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXDxunJazANC"
      },
      "source": [
        "Nest, we set up the trainer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPgdxsVbzANC"
      },
      "outputs": [],
      "source": [
        "#### YOUR COMMENTS BELOW (what are the congle lines doing?) ####\n",
        "grpo_trainer = GRPOTrainer(\n",
        "    args=config,\n",
        "    model=\"gavin124/gpt2-finetuned-cnn-summarization-v2\",\n",
        "    reward_funcs=reward_fn,\n",
        "    processing_class=tokenizer,\n",
        "    train_dataset=dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiraEWkMzANC"
      },
      "outputs": [],
      "source": [
        "#### YOUR CODE HERE: plot the loss and the rewards of the model training by accessing the trainer logs under grpo_trainer.state.log_history ####\n",
        "#### YOUR COMMENT HERE: do the plots indicate a trend towards successful training? ####\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebiXbMSgzANC"
      },
      "source": [
        "> **QUESTIONS:**\n",
        ">\n",
        "> 1. Suppose the plots of rewards below show training metrics for different runs of the summarization model training. Interpret what each of the plots tells us about training success; i.e., did the training run go well on this run? Do we expect to get good summaries? Why? Be concise!\n",
        "> 2. We have truncated the query articles to maximally 512 tokens. Given that we are using ROUGE with respect to ground truth summaries as a reward, why might this be problematic?\n",
        "> 3. GRPO is an algorithm improving over the PPO algorithm (Proximal Policy Optimization). What is they aspect that helps improve over PPO? Explain briefly.\n",
        "> 4. In the GRPO paper referenced above, on page 14, you can find the pseudo-algorithm for GRPO. For lines  1--4, 7--8 of the pseudo-code, write down what in our code above instatiates the concepts in the pseudo-code.\n",
        "> 5. In your own words, explain intuititvely what the role of the *group* in the algorithm is and why it is used. Use max. 3 sentences.\n",
        "> 6.  Name the parameter in the code above that determines the group size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f2SCRzizANC"
      },
      "source": [
        "![img](https://github.com/CogSciPrag/Understanding-LLMs-course/blob/main/understanding-llms/homework/data/rewards.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV9cfJVjzANC"
      },
      "source": [
        "## Exercise 3: First neural LM (20 points)\n",
        "\n",
        "Next to reading and understanding package documentations, a key skill for NLP researchers and practitioners is reading and critically assessing NLP literature. The density, but also the style of NLP literature has undergone a significant shift in the recent years with increasing acceleration of progress. Your task in this exercise is to read a paper about one of the first successful neural langauge models, understand its key architectural components and compare how these key components have evolved in modern systems that were discussed in the lecture.\n",
        "\n",
        "> Specifically, please read the paper by [Bengio et al. (2003)](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) and answer the following questions:\n",
        ">\n",
        "> * How were words / tokens represented? What is the difference / similarity to modern LLMs?\n",
        "> * How was the context represented? What is the difference / similarity to modern LLMs?\n",
        "> * What is the curse of dimensionality? Give a concrete example in the context of language modeling.\n",
        "> * Which training data was used? What is the difference / similarity to modern LLMs?\n",
        "> * Which components of the Bengio et al. (2003) model (if any) can be found in modern LMs?\n",
        ">\n",
        "\n",
        "Furthermore, your task is to carefully dissect the paper by Bengio et al. (2003) and analyse its structure and style in comparison to another more recent paper:  [Devlin et al. (2019) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805)\n",
        "\n",
        "**TASK:**\n",
        "\n",
        "> For each section of the Bengio et al. (2003) paper, what are key differences between the way it is written, the included contents, to the BERT paper (Devlin et al., 2019)? What are key similarities? Write max. 2 sentences per section.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8dCwz5IzANC"
      },
      "source": [
        "* In Bengio's, each word is turned into a continuous vector embedding, which the model learns during training. These vectors capture meaning based on how words appear together.\n",
        "\n",
        "  In modern models, words are also turned into embeddings, but these are dynamic and context-sensitive.\n",
        "\n",
        "  Similarity: Both use embeddings to represent words.\n",
        "\n",
        "  Difference: Bengio's embeddings are fixed once learned, while the latter change based on the surrounding context.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "* Bengio's model uses a fixed-size window of words (e.g. the last 3 words) to predict the next one, using a feedforward neural network.\n",
        "\n",
        "  In modern LLMs, context is captured using self-attention in transformers, allowing the model to consider the entire sequence.\n",
        "\n",
        "  Similarity- Both use context to make predictions.\n",
        "\n",
        "  Difference- Bengio's model uses a small window in one direction, while modern LLMs use deep and full-sequence context (uni- or bidirectional depending on the model).\n",
        "---\n",
        "\n",
        "* It means that the number of possible word combinations grows super fast as sentences get longer, making it hard for models to learn from limited data.\n",
        "\n",
        "  Example: If you try to model 10-word sentences from a vocabulary of 100,000 words, there are 100000^10 possibilities.\n",
        "\n",
        "  Bengio's model solves this by using embeddings, so similar word combinations share information.\n",
        "\n",
        "---\n",
        "\n",
        "  * Bengio trained their model on the Brown Corpus (1.18M words) and AP News (14M words).\n",
        "\n",
        "  Modern LLMs' are trained on massive datasets, with training corpora with hundreds of billions of words.\n",
        "\n",
        "  Similarity: Both use real-world text to train on.\n",
        "\n",
        "  Difference: Modern models are trained on much bigger and more diverse data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* 1. Word embeddings ie, the idea of turning words into vectors.\n",
        "\n",
        "  2. Neural networks for predicting words.\n",
        "\n",
        "  3. Joint learning of representations and language model.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "* Abstract\n",
        "\n",
        "  Bengio: Longer and more technical; explains the full model and results.\n",
        "\n",
        "  BERT: Shorter and clearer; quickly highlights what's new and impactful.\n",
        "\n",
        "* Introduction\n",
        "\n",
        "  Bengio: Focuses on the problem of language modeling and the curse of dimensionality.\n",
        "\n",
        "  BERT: Quickly outlines what's missing in earlier models and introduces BERT as a solution.\n",
        "\n",
        "* Methodology\n",
        "\n",
        "  Bengio: Explains the model step-by-step with formulas and diagrams.\n",
        "\n",
        "  BERT: Describes the Transformer, pre-training (MLM + NSP) and how fine-tuning works.\n",
        "\n",
        "* Experiments\n",
        "\n",
        "  Bengio: Tests on small datasets and compares perplexity with n-gram models.\n",
        "\n",
        "  BERT: Shows strong performance across many NLP benchmarks (GLUE, SQuAD, etc.).\n",
        "\n",
        "* Conclusion\n",
        "\n",
        "  Bengio: Reflects on what was achieved and where future research could go.\n",
        "\n",
        "  BERT: Emphasizes BERT's effectiveness and suggests it can be adapted to many tasks.\n",
        "\n",
        "* Writing Style\n",
        "\n",
        "  Bengio: Academic and more theoretical.\n",
        "\n",
        "  BERT: More modern and focused on practical outcomes and benchmarks.\n",
        "\n",
        "\n",
        "  * Similarities:\n",
        "    1. clear problem definition\n",
        "    2. model architecture explained and training details included\n",
        "    3. evaluation with benchmarks\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "understanding_llms",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}